{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "7d5c25a0dcd433e9174dbd40cc8162c4c651cca147fa234e40a811528338fdfd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter #但tensorboard好像还是tensorflow的产品\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10/', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifar10/', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "source": [
    "## 0、启动：tensorboard --logdir=runs （如果把runs文件夹保存着，那么随时可以展示结果。）\n",
    "## 1、展示一批图片，在IMAGES一栏"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#默认的log_dir就是runs，存放在本地\n",
    "writer = SummaryWriter('runs/fuck_tensorboard')\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image('4_ccifar10_images', img_grid)"
   ]
  },
  {
   "source": [
    "## 2、展示网络结构图，输入输出，在GRAPHS一栏"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close() #似乎是要close后才能看到graph"
   ]
  },
  {
   "source": [
    "## 3、可视化分析数据库分布，在PROJECTOR一栏"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(100, 32, 32, 3)\nwarning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# 可视化分析数据库分布\n",
    "#（注意有延迟的，可能要打开退出好几次才能看到）\n",
    "def select_n_random(data, labels, n=100):\n",
    "    assert len(data) == len(labels)\n",
    "    perm = torch.randperm(len(data))\n",
    "    print(data[perm][:n].shape)\n",
    "    tmp=data[perm][:n].transpose(0,3,1,2)\n",
    "    return torch.tensor(tmp), torch.tensor(labels)[perm][:n]\n",
    "\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "features = images.view(-1, 32*32*3)\n",
    "writer.add_embedding(features,  #就是把特征铺平，然后可视化PCA或者t-SNE\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images)\n",
    "writer.close()"
   ]
  },
  {
   "source": [
    "## 4、画loss之类的，在SCALARS一栏"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不重要，没必要看。helper functions\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    #就是随机取一批看看预测错的和对的。\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    \n",
    "            # 1000组样本记录一次loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i) #就是好多组figure编个号。\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "source": [
    "## 5、绘制PR曲线，显示在PR CURVES一栏"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs = []\n",
    "class_label = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_label.append(labels)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_label = torch.cat(class_label)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_truth = test_label == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_truth,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_label)"
   ]
  },
  {
   "source": [
    "## 6、权重直方图&权值可视化"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([6, 3, 5, 5])\ntorch.Size([18, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "writer.add_histogram(\"conv1.weight\",net.conv1.weight,0)\n",
    "writer.close()\n",
    "\n",
    "kernel=(net.conv1.weight)\n",
    "print(kernel.shape)\n",
    "kernel=kernel.view(18,5,5).unsqueeze(dim=1)\n",
    "print(kernel.shape)\n",
    "img_grid = torchvision.utils.make_grid(kernel,normalize=True)\n",
    "writer.add_image('kernel', img_grid)"
   ]
  },
  {
   "source": [
    "## 7、特征可视化"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "conv1\ntorch.Size([1, 6, 28, 28])\npool\nconv2\ntorch.Size([1, 16, 10, 10])\nfeature\n"
     ]
    }
   ],
   "source": [
    "img = next(iter(trainloader))[0][0]\n",
    "writer.add_image(\"1_img\",img)\n",
    "img=img.unsqueeze(dim=0)\n",
    "for name, layer in net._modules.items():\n",
    "    if name==\"fc1\": #我们只看前两层卷积后的特征\n",
    "        break\n",
    "    print(name)\n",
    "    img=layer(img)\n",
    "    if \"conv\" in name:\n",
    "        print(img.shape)\n",
    "        tmp=img.transpose(0,1) #把16个通道当成16张图片 #注意torch.transpose是交换两个维度！\n",
    "        img_grid = torchvision.utils.make_grid(tmp,normalize=True)\n",
    "        writer.add_image(f'{name}_ffeature_maps', img_grid, global_step=0)"
   ]
  },
  {
   "source": [
    "## (8、CAM可视化理解，意义不大)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.feature = nn.AvgPool2d(5) #\n",
    "        self.fc1 = nn.Linear(16 * 1 * 1, 10)#\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x0 = self.pool(F.relu(self.conv2(x)))#\n",
    "        x=self.feature(x0)#\n",
    "        x = torch.flatten(x, 1) \n",
    "        x = self.fc1(x)\n",
    "        return x,x0#\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "running_loss = 0.0\n",
    "for epoch in range(10): \n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs,_ = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    \n",
    "            writer.add_scalar('fuck loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([10, 16])\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/fuck')\n",
    "img = next(iter(testloader))[0][2].unsqueeze(dim=0) \n",
    "writer.add_image(\"CAM00\",img[0])\n",
    "idx,fea=net(img)\n",
    "_,idx=torch.max(idx,1)\n",
    "\n",
    "fea=fea[0] #16，5，5\n",
    "wei=net.fc1.weight\n",
    "print(wei.shape)\n",
    "wei=wei[idx][0]\n",
    "for i in range(9):\n",
    "    fea[i]*=wei[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "heatmap = fea.detach().numpy()\n",
    "heatmap = np.mean(heatmap, axis=0)\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "heatmap = cv2.resize(heatmap, (32,32))\n",
    "real_heatmap = np.uint8(255 * heatmap)\n",
    "real_heatmap = cv2.applyColorMap(real_heatmap, cv2.COLORMAP_JET)\n",
    "real_heatmap = real_heatmap.transpose(2,0,1)\n",
    "real_heatmap = torch.tensor(real_heatmap)\n",
    "heatmap = torch.tensor(heatmap)\n",
    "heatmap=heatmap.unsqueeze(dim=0)\n",
    "res=img[0]*0.5+real_heatmap\n",
    "writer.add_image(\"CAM01\",heatmap)\n",
    "writer.add_image(\"CAM02\",real_heatmap)\n",
    "writer.add_image(\"CAM03\",res)"
   ]
  }
 ]
}